
En 2025, il sera essentiel de maintenir une collaboration étroite et efficace avec les équipes de développement en Inde, notamment pour garantir la continuité et l’amélioration des initiatives liées à la surveillance. Il devra également continuer à renforcer les contrôles mis en place dans le cadre du projet VERDI, en veillant à l’exhaustivité des données et à la robustesse des processus existants, afin d’assurer une surveillance complète et conforme aux exigences de BNP Paribas. Enfin, il sera attendu qu’il reste force de proposition en identifiant des axes d’amélioration et en contribuant activement à l’innovation dans nos outils et méthodes.



Voici une mise à jour du commentaire global en incluant ses contributions à la mise en place des outils dans le cadre de la surveillance et du projet VERDI :

Commentaire global

Cette année, le collaborateur a joué un rôle crucial dans le succès de plusieurs projets stratégiques, notamment le projet VERDI. Il a su relever des défis complexes, notamment liés à la gestion et à la qualité des données dans un contexte réglementaire exigeant.

Dans le cadre du projet VERDI, il a mis en place un ensemble d’outils innovants pour garantir l’exhaustivité des données dans notre Data Warehouse. Ces outils ont permis :
	•	De suivre la chaîne complète de surveillance, depuis l’ingestion des données jusqu’à la production des alertes de market abuse.
	•	De monitorer toutes les étapes intermédiaires par lesquelles passent les données avant leur intégration dans les modèles de surveillance.
	•	D’assurer un contrôle accru de la qualité et de la traçabilité des données, en réduisant les risques d’anomalies et en facilitant les remédiations rapides.

Ces contributions ont non seulement renforcé la robustesse de nos chaînes de surveillance, mais elles ont également posé les bases pour une gestion plus proactive et transparente des données critiques. Son expertise et son engagement dans ce domaine ont permis à l’équipe de répondre aux attentes des régulateurs tout en instaurant une culture de rigueur et de performance autour de la data governance.

En parallèle, il a su gérer efficacement une équipe face à une forte pression, tout en assurant la formation des collaborateurs sur ces nouveaux outils et processus. Grâce à son leadership, les membres de l’équipe sont désormais mieux préparés pour maintenir et améliorer ces initiatives dans le futur.

En résumé, ce collaborateur s’est distingué cette année par son sens de l’innovation, sa capacité à mener à bien des projets stratégiques sous pression, et son engagement pour l’excellence opérationnelle. Ses contributions, notamment dans le cadre de VERDI, ont été déterminantes pour renforcer la conformité, la qualité des données et la performance globale de nos systèmes de surveillance.

Si vous souhaitez que j’ajoute ou ajuste certains éléments, je peux affiner davantage ce texte.



Voici une mise à jour de l’évaluation en tenant compte du projet dans le domaine de la trade surveillance :

Objectifs 2024
	1.	Assurer la continuité des activités locales en tant que manager :
	•	Superviser l’équipe à Paris, en assurant la bonne gestion des projets critiques.
	•	Maintenir une collaboration fluide entre Paris et New York.
	2.	Piloter le projet stratégique de trade surveillance :
	•	Revoir et renforcer toutes les chaînes de surveillance et les procédures liées à la data governance.
	•	S’assurer de l’exhaustivité des données conformément au mandat de record keeping et centraliser les flux pré-trade dans le Data Warehouse (DWH).
	•	Identifier et remédier aux lacunes dans les flux de données avec une forte pression réglementaire et des délais serrés.
	3.	Renforcer la qualité et le contrôle des données :
	•	Mettre en œuvre des initiatives visant à améliorer la qualité des données, leur contrôle et leur traçabilité.
	•	Garantir que tous les processus de surveillance couvrent l’ensemble des activités critiques de la banque d’investissement.
	4.	Former et autonomiser l’équipe sur les nouvelles initiatives :
	•	Former les membres de l’équipe sur les nouvelles procédures et initiatives mises en place.
	•	Assurer une adoption fluide des nouveaux processus pour garantir leur bon fonctionnement à long terme.
	5.	Encourager la collaboration et la gestion des talents :
	•	Maintenir une dynamique d’équipe positive malgré les exigences élevées.
	•	Soutenir le développement des collaborateurs et partager les meilleures pratiques.

Commentaire global

Cette année a été marquée par des défis complexes et une pression accrue, notamment avec le projet stratégique dans le domaine de la trade surveillance. En tant que manager local, ce collaborateur a joué un rôle central dans la révision des chaînes de surveillance et la mise en conformité avec des exigences réglementaires toujours plus élevées.

Le projet a nécessité une revue complète des processus de surveillance pour garantir l’exhaustivité des données dans notre Data Warehouse, la remédiation des lacunes identifiées dans des délais courts, et la mise en place de nouveaux flux répondant aux besoins de record keeping. Face à la complexité technique et à la pression réglementaire, ce collaborateur a su gérer efficacement les priorités, coordonner les efforts de l’équipe et assurer la livraison des résultats attendus.

Son leadership a également été essentiel dans la formation de l’équipe sur les nouvelles initiatives et leur adoption. Grâce à son implication, les membres de l’équipe sont désormais mieux équipés pour gérer ces nouveaux processus, garantissant une amélioration continue de la qualité et du contrôle des données.

En parallèle, il a maintenu une collaboration étroite avec les équipes à New York, jouant un rôle de relais crucial pour aligner les objectifs locaux et globaux. Malgré la charge de travail importante, il a su maintenir une dynamique positive au sein de l’équipe, favorisant une ambiance de travail collaborative et motivante.

En résumé, ce collaborateur a démontré une résilience remarquable, une capacité à gérer des projets d’envergure sous pression, et un engagement fort envers les objectifs stratégiques de l’entreprise. Son travail a non seulement permis de répondre aux exigences immédiates, mais a également posé les bases d’une amélioration durable des processus de surveillance et de gestion des données.

Je tiens à souligner son rôle clé dans le succès de cette année et à le remercier pour son professionnalisme et son implication dans ce projet stratégique.

Si vous souhaitez ajuster ou détailler davantage certains points, je peux affiner ce texte.

Voici une proposition pour structurer l’évaluation annuelle de ce collaborateur :

Objectifs 2024
	1.	Assurer la continuité des activités locales en tant que manager :
	•	Prendre en main les responsabilités de management de l’équipe à Paris.
	•	Superviser les projets critiques en cours, en s’assurant de leur bonne exécution dans les délais impartis.
	•	Maintenir une bonne communication entre l’équipe locale et les équipes à l’international (notamment à New York).
	2.	Gérer les projets complexes, notamment réglementaires :
	•	Piloter les sujets liés au réglementaire, en s’assurant de répondre aux exigences élevées de conformité et de qualité.
	•	Identifier et résoudre les obstacles, tout en gérant la pression associée à ces projets critiques.
	3.	Encourager la collaboration et le développement des membres de l’équipe :
	•	Soutenir le développement professionnel des collaborateurs.
	•	Maintenir une ambiance de travail positive malgré la charge importante de travail.
	4.	Faciliter la transition et maintenir une relation forte avec New York :
	•	Travailler en étroite collaboration avec le manager basé à New York (moi-même) pour garantir l’alignement global des équipes.
	•	Assurer un relais fluide et une communication efficace sur les projets transversaux.

Commentaire global

Cette année a marqué une transition majeure pour ce collaborateur, qui a assumé de nouvelles responsabilités managériales dans un contexte exigeant et parfois sous pression importante. Devenu le manager local à Paris, il a su s’adapter rapidement à son rôle en développant une organisation rigoureuse et en adoptant une approche proactive face aux nombreux défis.

Le collaborateur a montré une grande résilience face à la pression liée à des projets complexes, notamment ceux concernant des sujets réglementaires stratégiques pour la banque. Il a su gérer les attentes élevées des parties prenantes internes et externes tout en maintenant une qualité irréprochable dans la livraison des projets. Son leadership s’est également distingué par une excellente gestion de son équipe, en réussissant à maintenir une cohésion forte et une dynamique de travail positive, malgré la charge importante.

Sur le plan de la collaboration internationale, il a joué un rôle crucial en servant de relais efficace entre Paris et New York, permettant de garantir la continuité des activités et l’alignement stratégique. Cette capacité à travailler en synergie avec des équipes globales a été un atout majeur pour assurer le bon fonctionnement de nos projets.

En résumé, cette année a été particulièrement exigeante pour ce collaborateur, et il a su relever les défis avec brio. Son leadership, son sens de l’organisation et sa capacité à naviguer dans un environnement complexe et sous pression sont à souligner. Il a démontré qu’il est un pilier essentiel pour la réussite de nos projets et pour le fonctionnement harmonieux des équipes.

Je tiens à le féliciter pour ses performances remarquables cette année et pour son implication continue dans l’amélioration de nos processus et la gestion de nos projets.

Si vous avez des éléments supplémentaires ou des points spécifiques que vous souhaitez approfondir, n’hésitez pas à les préciser, et je pourrai ajuster ce texte en conséquence.



from dash import Dash, html, dcc, Output, Input
import dash_bootstrap_components as dbc

# Initialize the app
app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])  # Default Bootstrap theme

# Define light and dark themes
LIGHT_THEME = dbc.themes.BOOTSTRAP
DARK_THEME = dbc.themes.DARKLY

# App layout
app.layout = html.Div([
    dbc.Navbar(
        dbc.Container([
            dbc.NavbarBrand("Theme Switcher Dashboard", className="ms-2"),
            dcc.Switch(
                id="theme-switch",
                label="Dark Mode",
                value=False,  # Default to light mode
                style={"margin-left": "auto"},
            ),
        ]),
        color="primary",
        dark=True,  # Navbar always dark for contrast
    ),
    dbc.Container(
        id="main-content",
        className="mt-4",
        children=[
            html.H1("Hello, Dash!", id="header"),
            html.P("This is an example of a light/dark theme switcher."),
        ],
    )
])

# Callback to switch themes
@app.callback(
    Output("main-content", "style"),
    Output("header", "className"),
    Input("theme-switch", "value")
)
def switch_theme(dark_mode):
    if dark_mode:
        return {"backgroundColor": "#2b2b2b", "color": "#f0f0f0"}, "text-light"
    return {"backgroundColor": "#ffffff", "color": "#000000"}, "text-dark"


if __name__ == "__main__":
    app.run_server(debug=True)






import dash
from dash import dcc, html, Input, Output, State, ctx
import dash_bootstrap_components as dbc

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
app.title = "Dashboard with User Configuration"

# Sample configurations for demonstration
configurations = [
    {"id": 1, "name": "Default Configuration", "is_default": True},
    {"id": 2, "name": "Custom Configuration 1", "is_default": False},
    {"id": 3, "name": "Custom Configuration 2", "is_default": False},
]

# Counter for unique configuration IDs
config_id_counter = 4


def configuration_modal():
    """Layout for the configuration management modal."""
    return dbc.Modal(
        [
            dbc.ModalHeader(
                html.Div(
                    [
                        html.Span("Manage Configurations", style={"font-weight": "bold"}),
                        dbc.Button(
                            html.I(className="fas fa-plus"),
                            id="add-config-btn",
                            color="success",
                            size="sm",
                            className="ms-auto me-2",
                            title="Add Configuration",
                        ),
                    ],
                    style={"display": "flex", "align-items": "center"},
                )
            ),
            dbc.ModalBody(
                html.Div(id="configuration-list", children=[]),
                style={"max-height": "400px", "overflow-y": "auto"},
            ),
            dbc.ModalFooter(
                html.Div(
                    [
                        dbc.Button("Load Configuration", id="load-config-btn", color="primary", className="me-2"),
                        dbc.Button("Close", id="close-modal-btn", className="ms-auto"),
                    ],
                    style={"display": "flex", "justify-content": "flex-end"},
                )
            ),
        ],
        id="config-modal",
        is_open=False,
        size="md",
    )


app.layout = html.Div(
    [
        dcc.Location(id="url"),
        dbc.NavbarSimple(
            brand="Dashboard",
            children=[
                dbc.NavItem(dbc.NavLink("Logout", href="#")),
                dbc.NavItem(dbc.NavLink("Manage Configurations", id="open-modal-btn")),
            ],
            className="mb-4",
        ),
        html.Div(
            id="dashboard-content",
            children="Content of the Dashboard",
            style={"padding": "20px"},
        ),
        configuration_modal(),
    ]
)


@app.callback(
    Output("config-modal", "is_open"),
    [Input("open-modal-btn", "n_clicks"), Input("close-modal-btn", "n_clicks")],
    [State("config-modal", "is_open")],
)
def toggle_modal(open_click, close_click, is_open):
    """Toggle the configuration modal."""
    if open_click or close_click:
        return not is_open
    return is_open


@app.callback(
    Output("configuration-list", "children"),
    [
        Input("add-config-btn", "n_clicks"),
        Input({"type": "default-star", "index": dash.ALL}, "n_clicks"),
        Input({"type": "remove-config", "index": dash.ALL}, "n_clicks"),
    ],
    [State("configuration-list", "children")],
)
def update_configuration_list(add_click, star_clicks, remove_clicks, current_children):
    """Update the configuration list displayed in the modal."""
    global configurations, config_id_counter

    # Handle add configuration
    if add_click and ctx.triggered_id == "add-config-btn":
        new_config = {
            "id": config_id_counter,
            "name": f"New Configuration {config_id_counter}",
            "is_default": False,
        }
        configurations.append(new_config)
        config_id_counter += 1

    # Handle default star click
    if ctx.triggered_id and "default-star" in str(ctx.triggered_id):
        index = ctx.triggered_id["index"]
        for config in configurations:
            config["is_default"] = False
        configurations[index]["is_default"] = True

    # Handle remove button click
    if ctx.triggered_id and "remove-config" in str(ctx.triggered_id):
        index = ctx.triggered_id["index"]
        configurations = [config for i, config in enumerate(configurations) if i != index]

    # Generate the updated configuration list
    return [
        html.Div(
            id=f"config-{config['id']}",
            children=[
                html.Span(config["name"], style={"flex-grow": 1}),
                dbc.Button(
                    html.I(
                        className="fas fa-star"
                        if config["is_default"]
                        else "far fa-star"
                    ),
                    id={"type": "default-star", "index": i},
                    color="warning" if config["is_default"] else "secondary",
                    size="sm",
                    className="ms-2",
                    title="Set as Default",
                ),
                dbc.Button(
                    html.I(className="fas fa-trash"),
                    id={"type": "remove-config", "index": i},
                    color="danger",
                    size="sm",
                    className="ms-2",
                    title="Remove Configuration",
                ),
            ],
            style={"display": "flex", "align-items": "center", "margin-bottom": "10px"},
        )
        for i, config in enumerate(configurations)
    ]


@app.callback(
    Output("dashboard-content", "children"),
    Input("load-config-btn", "n_clicks"),
)
def load_configuration(n_clicks):
    """Load the selected configuration."""
    if n_clicks:
        default_config = next((c for c in configurations if c["is_default"]), None)
        if default_config:
            return f"Loaded Configuration: {default_config['name']}"
        return "No default configuration set."
    return dash.no_update


if __name__ == "__main__":
    app.run_server(debug=True)





import dash
from dash import dcc, html, Input, Output, State, callback_context, ALL
import dash_bootstrap_components as dbc

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
app.title = "Dashboard with User Configuration"

# Sample configurations for demonstration
configurations = [
    {"id": 1, "name": "Default Configuration", "is_default": True},
    {"id": 2, "name": "Custom Configuration 1", "is_default": False},
    {"id": 3, "name": "Custom Configuration 2", "is_default": False},
]

config_id_counter = 4


def configuration_modal():
    """Layout for the configuration management modal."""
    return dbc.Modal(
        [
            dbc.ModalHeader(
                html.Div(
                    [
                        html.Span("Manage Configurations", style={"font-weight": "bold"}),
                        dbc.Button(
                            html.I(className="fas fa-plus"),
                            id="add-config-btn",
                            color="success",
                            size="sm",
                            className="ms-auto me-2",
                            title="Add Configuration",
                        ),
                        dbc.Button(
                            html.I(className="fas fa-file-import"),
                            id="import-config-btn",
                            color="primary",
                            size="sm",
                            className="me-2",
                            title="Import Other User Configuration",
                        ),
                    ],
                    style={"display": "flex", "align-items": "center"},
                )
            ),
            dbc.ModalBody(
                html.Div(id="configuration-list", children=[]),
                style={"max-height": "400px", "overflow-y": "auto"},
            ),
            dbc.ModalFooter(
                dbc.Button("Load Configuration", id="load-config-btn", color="primary"),
                dbc.Button("Close", id="close-modal-btn", className="ms-auto"),
            ),
        ],
        id="config-modal",
        is_open=False,
        size="md",
    )


app.layout = html.Div(
    [
        dbc.NavbarSimple(
            brand="Dashboard",
            children=[
                dbc.NavItem(dbc.NavLink("Logout", href="#")),
                dbc.NavItem(dbc.NavLink("Manage Configurations", id="open-modal-btn")),
            ],
            className="mb-4",
        ),
        html.Div(
            id="dashboard-content",
            children="Content of the Dashboard",
            style={"padding": "20px"},
        ),
        configuration_modal(),
    ]
)


@app.callback(
    Output("config-modal", "is_open"),
    [Input("open-modal-btn", "n_clicks"), Input("close-modal-btn", "n_clicks")],
    [State("config-modal", "is_open")],
)
def toggle_modal(open_click, close_click, is_open):
    """Toggle the configuration modal."""
    if open_click or close_click:
        return not is_open
    return is_open


@app.callback(
    Output("configuration-list", "children"),
    [
        Input("open-modal-btn", "n_clicks"),
        Input("add-config-btn", "n_clicks"),
        Input("import-config-btn", "n_clicks"),
        Input({"type": "default-star", "index": ALL}, "n_clicks"),
        Input({"type": "remove-config", "index": ALL}, "n_clicks"),
    ],
)
def update_configuration_list(open_click, add_click, import_click, star_clicks, remove_clicks):
    """Update the configuration list displayed in the modal."""
    global configurations, config_id_counter

    ctx = callback_context
    if not ctx.triggered:
        return [
            generate_config_row(config, idx) for idx, config in enumerate(configurations)
        ]

    triggered_id = ctx.triggered[0]["prop_id"].split(".")[0]

    # Handle add configuration
    if triggered_id == "add-config-btn":
        new_config = {
            "id": config_id_counter,
            "name": f"New Configuration {config_id_counter}",
            "is_default": False,
        }
        configurations.append(new_config)
        config_id_counter += 1

    # Handle default star click
    elif triggered_id.startswith("{\"type\":\"default-star\""):
        for config in configurations:
            config["is_default"] = False
        index = int(ctx.triggered[0]["prop_id"].split(":")[1].split("}")[0])
        configurations[index]["is_default"] = True

    # Handle remove button click
    elif triggered_id.startswith("{\"type\":\"remove-config\""):
        index = int(ctx.triggered[0]["prop_id"].split(":")[1].split("}")[0])
        config_id_to_remove = configurations[index]["id"]
        configurations = [
            config for config in configurations if config["id"] != config_id_to_remove
        ]

    # Generate the updated configuration list
    return [
        generate_config_row(config, idx) for idx, config in enumerate(configurations)
    ]


def generate_config_row(config, idx):
    """Generate a single configuration row for the modal."""
    return html.Div(
        id=f"config-{config['id']}",
        children=[
            html.Span(config["name"], style={"flex-grow": 1}),
            dbc.Button(
                html.I(
                    className="fas fa-star" if config["is_default"] else "far fa-star"
                ),
                id={"type": "default-star", "index": idx},
                color="warning" if config["is_default"] else "secondary",
                size="sm",
                className="me-2",
                title="Set as Default",
            ),
            dbc.Button(
                html.I(className="fas fa-trash"),
                id={"type": "remove-config", "index": idx},
                color="danger",
                size="sm",
                className="ms-2",
                title="Remove Configuration",
            ),
        ],
        style={"display": "flex", "align-items": "center", "margin-bottom": "10px"},
    )


if __name__ == "__main__":
    app.run_server(debug=True)




from dash import Dash, html, dcc, Input, Output, State

app = Dash(__name__)

app.layout = html.Div(
    [
        html.Button("Manage Configurations", id="open-modal-btn", className="btn btn-primary"),
        dcc.Store(id="selected-config"),
        dcc.Store(
            id="configurations",
            data=[
                {"name": "Config 1", "is_default": True},
                {"name": "Config 2", "is_default": False},
                {"name": "Config 3", "is_default": False},
            ],
        ),
        html.Div(id="modal", style={"display": "none"}),
    ]
)


@app.callback(
    Output("modal", "style"),
    Output("modal", "children"),
    Input("open-modal-btn", "n_clicks"),
    State("configurations", "data"),
)
def open_modal(n_clicks, configurations):
    if not n_clicks:
        return {"display": "none"}, None

    configuration_list = html.Div(
        [
            html.Div(
                [
                    html.Div(
                        config["name"],
                        className="config-name",
                        style={"flex": "1", "cursor": "pointer"},
                    ),
                    html.I(
                        className="fa-solid fa-star" if config["is_default"] else "fa-regular fa-star",
                        id={"type": "set-default", "index": i},
                        style={"cursor": "pointer", "margin-right": "10px", "color": "gold" if config["is_default"] else "gray"},
                    ),
                    html.I(
                        className="fa-solid fa-trash",
                        id={"type": "remove-config", "index": i},
                        style={"cursor": "pointer"},
                    ),
                ],
                className="config-row",
                style={
                    "display": "flex",
                    "align-items": "center",
                    "justify-content": "space-between",
                    "padding": "5px 10px",
                    "border": "1px solid #ddd",
                    "border-radius": "5px",
                    "margin-bottom": "5px",
                },
            )
            for i, config in enumerate(configurations)
        ]
    )

    modal_content = html.Div(
        [
            html.Div(
                [
                    html.Button(
                        html.I(className="fa-solid fa-plus"),
                        id="add-config-btn",
                        className="btn btn-success",
                        title="Add Configuration",
                        style={"margin-right": "10px"},
                    ),
                    html.Div(
                        [
                            dcc.Input(
                                id="user-id-input",
                                type="text",
                                placeholder="User ID",
                                style={"margin-right": "10px"},
                            ),
                            dcc.Input(
                                id="config-name-input",
                                type="text",
                                placeholder="Configuration Name",
                                style={"margin-right": "10px"},
                            ),
                            html.Button(
                                html.I(className="fa-solid fa-download"),
                                id="import-config-btn",
                                className="btn btn-info",
                                title="Import Configuration",
                            ),
                        ],
                        style={"display": "flex", "align-items": "center"},
                    ),
                ],
                style={"display": "flex", "align-items": "center", "margin-bottom": "20px"},
            ),
            configuration_list,
            html.Div(
                html.Button("Load Configuration", id="load-config-btn", className="btn btn-primary"),
                style={"text-align": "right", "margin-top": "20px"},
            ),
        ],
        style={
            "background-color": "white",
            "padding": "20px",
            "border-radius": "10px",
            "max-width": "500px",
            "margin": "auto",
            "box-shadow": "0 4px 6px rgba(0, 0, 0, 0.1)",
        },
    )

    return {"display": "block"}, modal_content


if __name__ == "__main__":
    app.run(debug=True)





from dash import Dash, html, dcc, Input, Output, State

app = Dash(__name__)

app.layout = html.Div(
    [
        html.Button("Manage Configurations", id="open-modal-btn", className="btn btn-primary"),
        dcc.Store(id="selected-config"),
        dcc.Store(
            id="configurations",
            data=[
                {"name": "Config 1", "is_default": True},
                {"name": "Config 2", "is_default": False},
                {"name": "Config 3", "is_default": False},
            ],
        ),
        html.Div(id="modal", style={"display": "none"}),
    ]
)


@app.callback(
    Output("modal", "style"),
    Output("modal", "children"),
    Input("open-modal-btn", "n_clicks"),
    State("configurations", "data"),
)
def open_modal(n_clicks, configurations):
    if not n_clicks:
        return {"display": "none"}, None

    configuration_list = html.Div(
        [
            html.Div(
                [
                    html.Div(
                        config["name"],
                        className="config-name",
                        style={"flex": "1", "cursor": "pointer"},
                    ),
                    html.I(
                        className="bi bi-star-fill" if config["is_default"] else "bi bi-star",
                        id={"type": "set-default", "index": i},
                        style={"cursor": "pointer", "margin-right": "10px", "color": "gold" if config["is_default"] else "gray"},
                    ),
                    html.I(
                        className="bi bi-trash",
                        id={"type": "remove-config", "index": i},
                        style={"cursor": "pointer"},
                    ),
                ],
                className="config-row",
                style={
                    "display": "flex",
                    "align-items": "center",
                    "justify-content": "space-between",
                    "padding": "5px 10px",
                    "border": "1px solid #ddd",
                    "border-radius": "5px",
                    "margin-bottom": "5px",
                },
            )
            for i, config in enumerate(configurations)
        ]
    )

    modal_content = html.Div(
        [
            html.Div(
                [
                    html.Button(
                        html.I(className="bi bi-plus-circle"),
                        id="add-config-btn",
                        className="btn btn-success",
                        title="Add Configuration",
                        style={"margin-right": "10px"},
                    ),
                    html.Div(
                        [
                            dcc.Input(
                                id="user-id-input",
                                type="text",
                                placeholder="User ID",
                                style={"margin-right": "10px"},
                            ),
                            dcc.Input(
                                id="config-name-input",
                                type="text",
                                placeholder="Configuration Name",
                                style={"margin-right": "10px"},
                            ),
                            html.Button(
                                html.I(className="bi bi-download"),
                                id="import-config-btn",
                                className="btn btn-info",
                                title="Import Configuration",
                            ),
                        ],
                        style={"display": "flex", "align-items": "center"},
                    ),
                ],
                style={"display": "flex", "align-items": "center", "margin-bottom": "20px"},
            ),
            configuration_list,
            html.Div(
                html.Button("Load Configuration", id="load-config-btn", className="btn btn-primary"),
                style={"text-align": "right", "margin-top": "20px"},
            ),
        ],
        style={
            "background-color": "white",
            "padding": "20px",
            "border-radius": "10px",
            "max-width": "500px",
            "margin": "auto",
            "box-shadow": "0 4px 6px rgba(0, 0, 0, 0.1)",
        },
    )

    return {"display": "block"}, modal_content


if __name__ == "__main__":
    app.run(debug=True)








import dash
from dash import dcc, html, Input, Output, State, callback_context
import dash_bootstrap_components as dbc

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
app.title = "Dashboard with User Configuration"

# Sample configurations for demonstration
configurations = [
    {"id": 1, "name": "Default Configuration", "is_default": True},
    {"id": 2, "name": "Custom Configuration 1", "is_default": False},
    {"id": 3, "name": "Custom Configuration 2", "is_default": False},
]

# Counter for unique configuration IDs
config_id_counter = 4

selected_configuration = None


def configuration_modal():
    """Layout for the configuration management modal."""
    return dbc.Modal(
        [
            dbc.ModalHeader(
                html.Div(
                    [
                        html.Span("Manage Configurations", style={"font-weight": "bold"}),
                        dbc.Button(
                            html.I(className="fas fa-plus"),
                            id="add-config-btn",
                            color="success",
                            size="sm",
                            className="ms-auto me-2",
                            title="Add Configuration",
                        ),
                        dbc.Button(
                            html.I(className="fas fa-file-import"),
                            id="import-config-btn",
                            color="primary",
                            size="sm",
                            className="me-2",
                            title="Import Other User Configuration",
                        ),
                    ],
                    style={"display": "flex", "align-items": "center"},
                )
            ),
            dbc.ModalBody(
                html.Div(id="configuration-list", children=[]),
                style={"max-height": "400px", "overflow-y": "auto"},
            ),
            dbc.ModalFooter(
                dbc.Button("Load Configuration", id="load-config-btn", color="primary"),
                dbc.Button("Close", id="close-modal-btn", className="ms-auto"),
            ),
        ],
        id="config-modal",
        is_open=False,
        size="md",
    )


app.layout = html.Div(
    [
        dcc.Location(id="url"),
        dbc.NavbarSimple(
            brand="Dashboard",
            children=[
                dbc.NavItem(dbc.NavLink("Logout", href="#")),
                dbc.NavItem(dbc.NavLink("Manage Configurations", id="open-modal-btn")),
            ],
            className="mb-4",
        ),
        html.Div(
            id="dashboard-content",
            children="Content of the Dashboard",
            style={"padding": "20px"},
        ),
        configuration_modal(),
    ]
)


@app.callback(
    Output("config-modal", "is_open"),
    [Input("open-modal-btn", "n_clicks"), Input("close-modal-btn", "n_clicks")],
    [State("config-modal", "is_open")],
)
def toggle_modal(open_click, close_click, is_open):
    """Toggle the configuration modal."""
    if open_click or close_click:
        return not is_open
    return is_open


@app.callback(
    Output("configuration-list", "children"),
    [
        Input("open-modal-btn", "n_clicks"),
        Input("add-config-btn", "n_clicks"),
        Input("import-config-btn", "n_clicks"),
        Input({"type": "default-star", "index": ALL}, "n_clicks"),
        Input({"type": "remove-config", "index": ALL}, "n_clicks"),
    ],
    [State("configuration-list", "children")],
)
def update_configuration_list(
    open_click, add_click, import_click, star_clicks, remove_clicks, current_children
):
    """Update the configuration list displayed in the modal."""
    global configurations, config_id_counter

    ctx = callback_context
    if not ctx.triggered:
        return current_children

    triggered_id = ctx.triggered[0]["prop_id"].split(".")[0]

    # Handle add configuration
    if triggered_id == "add-config-btn":
        new_config = {
            "id": config_id_counter,
            "name": f"New Configuration {config_id_counter}",
            "is_default": False,
        }
        configurations.append(new_config)
        config_id_counter += 1

    # Handle import configuration
    elif triggered_id == "import-config-btn":
        imported_config = {
            "id": config_id_counter,
            "name": f"Imported Configuration {config_id_counter}",
            "is_default": False,
        }
        configurations.append(imported_config)
        config_id_counter += 1

    # Handle default star click
    elif triggered_id.startswith("{\"type\":\"default-star\""):
        for config in configurations:
            config["is_default"] = False
        index = int(ctx.triggered[0]["prop_id"].split(":")[1].split("}")[0])
        configurations[index]["is_default"] = True

    # Handle remove button click
    elif triggered_id.startswith("{\"type\":\"remove-config\""):
        index = int(ctx.triggered[0]["prop_id"].split(":")[1].split("}")[0])
        configurations = [config for config in configurations if config["id"] != index]

    # Generate the updated configuration list
    return [
        html.Div(
            id=f"config-{config['id']}",
            children=[
                dbc.Button(
                    html.I(
                        className="fas fa-star"
                        if config["is_default"]
                        else "far fa-star"
                    ),
                    id={"type": "default-star", "index": i},
                    color="warning" if config["is_default"] else "secondary",
                    size="sm",
                    className="me-2",
                    title="Set as Default",
                ),
                html.Span(config["name"], style={"flex-grow": 1}),
                dbc.Button(
                    html.I(className="fas fa-trash"),
                    id={"type": "remove-config", "index": i},
                    color="danger",
                    size="sm",
                    className="ms-2",
                    title="Remove Configuration",
                ),
            ],
            style={"display": "flex", "align-items": "center", "margin-bottom": "10px"},
        )
        for i, config in enumerate(configurations)
    ]


@app.callback(
    Output("dashboard-content", "children"),
    Input("load-config-btn", "n_clicks"),
    [State("configuration-list", "children")],
)
def load_configuration(n_clicks, children):
    """Load the selected configuration."""
    global selected_configuration
    if n_clicks:
        return f"Loaded Configuration: {selected_configuration or 'None Selected'}"
    return dash.no_update


if __name__ == "__main__":
    app.run_server(debug=True)












import dash
from dash import dcc, html, Input, Output, State, callback_context
import dash_bootstrap_components as dbc

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
app.title = "Dashboard with User Configuration"

# Sample configurations for demonstration
configurations = [
    {"id": 1, "name": "Default Configuration", "is_default": True},
    {"id": 2, "name": "Custom Configuration 1", "is_default": False},
    {"id": 3, "name": "Custom Configuration 2", "is_default": False},
]

# Counter for unique configuration IDs
config_id_counter = 4


def configuration_modal():
    """Layout for the configuration management modal."""
    return dbc.Modal(
        [
            dbc.ModalHeader("Manage Configurations"),
            dbc.ModalBody(
                children=[
                    dbc.Button(
                        "Add Configuration",
                        id="add-config-btn",
                        color="primary",
                        className="mb-3",
                    ),
                    html.Div(id="configuration-list", children=[]),
                ]
            ),
            dbc.ModalFooter(
                dbc.Button("Close", id="close-modal-btn", className="ms-auto")
            ),
        ],
        id="config-modal",
        is_open=False,
        size="lg",
    )


app.layout = html.Div(
    [
        dcc.Location(id="url"),
        dbc.NavbarSimple(
            brand="Dashboard",
            children=[
                dbc.NavItem(dbc.NavLink("Logout", href="#")),
                dbc.NavItem(dbc.NavLink("Manage Configurations", id="open-modal-btn")),
            ],
            className="mb-4",
        ),
        html.Div(
            id="dashboard-content",
            children="Content of the Dashboard",
            style={"padding": "20px"},
        ),
        configuration_modal(),
    ]
)


@app.callback(
    Output("config-modal", "is_open"),
    [Input("open-modal-btn", "n_clicks"), Input("close-modal-btn", "n_clicks")],
    [State("config-modal", "is_open")],
)
def toggle_modal(open_click, close_click, is_open):
    """Toggle the configuration modal."""
    if open_click or close_click:
        return not is_open
    return is_open


@app.callback(
    Output("configuration-list", "children"),
    [
        Input("open-modal-btn", "n_clicks"),
        Input({"type": "remove-config", "index": dash.ALL}, "n_clicks"),
        Input("add-config-btn", "n_clicks"),
    ],
    [
        State("configuration-list", "children"),
        State("dashboard-content", "children"),  # Current dashboard state
    ],
)
def manage_configurations(open_click, remove_clicks, add_click, current_children, current_settings):
    """Update the configuration list displayed in the modal."""
    global configurations, config_id_counter

    ctx = callback_context
    if not ctx.triggered:
        return current_children

    triggered_id = ctx.triggered[0]["prop_id"].split(".")[0]

    if "remove-config" in triggered_id:
        # Remove the specified configuration
        index = int(triggered_id.split(":")[-1].replace('"}', ""))
        configurations = [config for config in configurations if config["id"] != index]

    if triggered_id == "add-config-btn":
        # Add a new configuration with the current settings
        new_config = {
            "id": config_id_counter,
            "name": f"New Configuration {config_id_counter}",
            "is_default": False,
        }
        configurations.append(new_config)
        config_id_counter += 1

    # Generate the configuration list
    config_list = []
    for config in configurations:
        config_row = html.Div(
            id=f"config-{config['id']}",
            children=[
                html.Span(
                    "★" if config["is_default"] else "☆",
                    style={"color": "gold" if config["is_default"] else "gray", "margin-right": "10px"},
                ),
                html.Span(config["name"], style={"margin-right": "20px"}),
                dbc.Button(
                    "Remove",
                    id={"type": "remove-config", "index": config["id"]},
                    color="danger",
                    size="sm",
                    className="ms-2",
                ),
            ],
            style={"display": "flex", "align-items": "center", "margin-bottom": "10px"},
        )
        config_list.append(config_row)

    return config_list


if __name__ == "__main__":
    app.run_server(debug=True)

















To allow users to save their current dashboard settings as a new configuration, we can add a Save Configuration button. When users click this button, a new configuration will be created with the current settings.

Here’s the updated code with the Save Configuration feature:

import dash
from dash import dcc, html, Input, Output, State, callback_context
import dash_bootstrap_components as dbc

app = dash.Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])
app.title = "Dashboard with User Configuration"

# Layout for the modal window
def configuration_modal():
    return dbc.Modal(
        [
            dbc.ModalHeader("Manage Configurations"),
            dbc.ModalBody(
                [
                    html.Div(
                        id="configuration-list",
                        children=[],
                        style={"margin-bottom": "20px"},
                    ),
                    dbc.Input(
                        id="new-config-name",
                        placeholder="Enter configuration name",
                        type="text",
                    ),
                    dbc.Button(
                        "Add Configuration", id="add-config-btn", color="primary", className="mt-2"
                    ),
                    dbc.Button(
                        "Save Current Settings", id="save-config-btn", color="success", className="mt-2 ms-2"
                    ),
                ]
            ),
            dbc.ModalFooter(
                dbc.Button("Close", id="close-modal-btn", className="ms-auto", n_clicks=0),
            ),
        ],
        id="config-modal",
        is_open=False,
        size="lg",
    )


# Sample initial configurations
configurations = [
    {"id": 1, "name": "Default Configuration"},
    {"id": 2, "name": "Custom Configuration"},
]

# Layout of the main app
app.layout = html.Div(
    [
        dcc.Location(id="url"),
        dbc.NavbarSimple(
            brand="Dashboard",
            children=[
                dbc.NavItem(dbc.NavLink("Logout", href="#")),
                dbc.NavItem(dbc.NavLink("Manage Configurations", id="open-modal-btn")),
            ],
            className="mb-4",
        ),
        html.Div(
            id="dashboard-content",
            children="Content of the Dashboard",
            style={"padding": "20px"},
        ),
        configuration_modal(),
    ]
)


# Callbacks for managing the modal and configurations
@app.callback(
    Output("config-modal", "is_open"),
    [Input("open-modal-btn", "n_clicks"), Input("close-modal-btn", "n_clicks")],
    [State("config-modal", "is_open")],
)
def toggle_modal(open_click, close_click, is_open):
    if open_click or close_click:
        return not is_open
    return is_open


@app.callback(
    Output("configuration-list", "children"),
    [
        Input("add-config-btn", "n_clicks"),
        Input("save-config-btn", "n_clicks"),
        Input("configuration-list", "children"),
    ],
    [State("new-config-name", "value"), State("dashboard-content", "children")],
)
def manage_configurations(add_click, save_click, current_children, new_name, current_dashboard_settings):
    ctx = callback_context
    triggered = ctx.triggered[0]["prop_id"].split(".")[0]
    config_children = current_children or []

    if triggered == "add-config-btn" and new_name:
        # Add a new configuration with a specified name
        new_id = len(config_children) + 1
        config_children.append(
            html.Div(
                id=f"config-{new_id}",
                children=[
                    dbc.InputGroup(
                        [
                            dbc.Input(
                                value=new_name,
                                id=f"config-name-{new_id}",
                                placeholder="Configuration Name",
                            ),
                            dbc.Button(
                                "Load", id=f"load-config-{new_id}", color="success"
                            ),
                            dbc.Button(
                                "Rename", id=f"rename-config-{new_id}", color="secondary"
                            ),
                            dbc.Button(
                                "Share", id=f"share-config-{new_id}", color="info"
                            ),
                            dbc.Button(
                                "Delete", id=f"delete-config-{new_id}", color="danger"
                            ),
                        ],
                        className="mb-2",
                    )
                ],
            )
        )

    if triggered == "save-config-btn":
        # Save the current dashboard settings as a new configuration
        new_id = len(config_children) + 1
        config_name = f"Configuration {new_id} (Saved)"
        config_children.append(
            html.Div(
                id=f"config-{new_id}",
                children=[
                    dbc.InputGroup(
                        [
                            dbc.Input(
                                value=config_name,
                                id=f"config-name-{new_id}",
                                placeholder="Configuration Name",
                            ),
                            dbc.Button(
                                "Load", id=f"load-config-{new_id}", color="success"
                            ),
                            dbc.Button(
                                "Rename", id=f"rename-config-{new_id}", color="secondary"
                            ),
                            dbc.Button(
                                "Share", id=f"share-config-{new_id}", color="info"
                            ),
                            dbc.Button(
                                "Delete", id=f"delete-config-{new_id}", color="danger"
                            ),
                        ],
                        className="mb-2",
                    )
                ],
            )
        )

    return config_children


@app.callback(
    Output("dashboard-content", "children"),
    [Input({"type": "load-config", "index": dash.ALL}, "n_clicks")],
    [State("configuration-list", "children")],
)
def load_configuration(load_clicks, config_children):
    ctx = callback_context
    if not ctx.triggered:
        return "Content of the Dashboard"

    triggered_id = ctx.triggered[0]["prop_id"].split(".")[0]
    if "load-config" in triggered_id:
        index = int(triggered_id.split(":")[-1].replace('"}', ""))
        config_name = config_children[index]["props"]["children"][0]["props"]["children"][0]["props"]["value"]
        return f"Dashboard loaded with configuration: {config_name}"

    return "Content of the Dashboard"


if __name__ == "__main__":
    app.run_server(debug=True)

Updates:
	1.	Save Current Settings Button:
	•	Added a new button labeled “Save Current Settings” in the modal.
	•	Clicking this button creates a new configuration with a name like "Configuration X (Saved)" based on the current dashboard settings.
	2.	Manage Saved Configurations:
	•	The new configuration is added to the list of available configurations, and users can manage it like others.
	3.	Example Behavior:
	•	When the Save Current Settings button is clicked, it saves the current dashboard state as a new configuration.
	•	The new configuration can be renamed, shared, deleted, or loaded as with others.

This implementation allows users to save their current settings dynamically and manage them seamlessly. Let me know if you need further refinements or want to extend functionality!





from dash import Dash, html, dcc

app = Dash(__name__)

app.layout = html.Div(
    [
        dcc.Interval(id="interval-component", interval=2000, n_intervals=0),
        html.Div("Monitoring HTTP response codes...", id="status-text", style={"padding": "20px"}),
        html.Script(
            """
            (function() {
                const originalFetch = window.fetch;

                // Override the fetch function
                window.fetch = async function(...args) {
                    const response = await originalFetch(...args);

                    // Check if it's a Dash callback response
                    if (args[0].includes('_dash-update-component')) {
                        const container = document.getElementById('main-container');
                        const statusText = document.getElementById('status-text');

                        if (response.status >= 200 && response.status < 300) {
                            // Success
                            container.style.backgroundColor = "white";
                            statusText.innerText = "Callback succeeded! HTTP " + response.status;
                        } else {
                            // Failure
                            container.style.backgroundColor = "red";
                            statusText.innerText = "Callback failed! HTTP " + response.status;
                        }
                    }
                    return response;
                };
            })();
            """
        ),
    ],
    id="main-container",
    style={"backgroundColor": "white", "height": "100vh"},
)

if __name__ == "__main__":
    app.run(debug=True)



To ensure your JSON request to a WebSocket does not contain any invalid or problematic characters, you can follow these steps:

1. Validate the JSON Format

Use a JSON library in your programming language to validate the structure of your JSON. For example:
	•	Python: Use the json module:

import json

try:
    # Assuming `data` is the JSON you want to send
    json.dumps(data)  # Converts the Python object to a JSON string
except (TypeError, ValueError) as e:
    print(f"Invalid JSON: {e}")


	•	JavaScript: Use JSON.stringify:

try {
    const jsonString = JSON.stringify(data);
} catch (error) {
    console.error("Invalid JSON:", error);
}



2. Escape Special Characters

Ensure no control characters (e.g., newline \n, tab \t, or backspace \b) are unintentionally included. Libraries like Python’s json.dumps or JavaScript’s JSON.stringify handle this automatically by escaping these characters.

3. Sanitize Input

If your JSON includes user input or dynamic data, sanitize it to avoid unwanted characters. For instance:
	•	Remove or replace invalid characters:

def sanitize_string(s):
    return ''.join(c for c in s if c.isprintable())



4. Use UTF-8 Encoding

Ensure all strings are UTF-8 encoded. This prevents issues with special characters or unsupported encodings:

json_string = json.dumps(data, ensure_ascii=False).encode('utf-8')

5. Test for Invalid Characters

Check for characters that might be problematic for WebSocket communication, like non-UTF-8 or control characters:

import re

def contains_invalid_chars(s):
    return bool(re.search(r'[^\x20-\x7E]', s))  # Matches non-ASCII printable characters

6. Use JSON Validation Tools

If needed, test your JSON with external validators like https://jsonlint.com/ or write unit tests to validate common payloads.

By combining these strategies, you can ensure your JSON payload is clean and well-structured for WebSocket communication.




import pandas as pd

def get_diff_with_status(df_old: pd.DataFrame, df_new: pd.DataFrame, match_cols: list) -> pd.DataFrame:
    """
    Compares two DataFrames and identifies updated, new, and removed rows in a single DataFrame.
    
    Parameters:
    - df_old (pd.DataFrame): The original DataFrame.
    - df_new (pd.DataFrame): The new DataFrame with potential updates.
    - match_cols (list): List of columns used to identify matching rows.
    
    Returns:
    - pd.DataFrame: A DataFrame containing rows from both DataFrames with a status column indicating "new", "removed", or "updated".
    """
    
    # Perform a full outer merge to track changes in all rows
    merged_df = df_old.merge(df_new, on=match_cols, suffixes=('_old', '_new'), how='outer', indicator=True)
    
    # Create a status column to describe the type of change
    merged_df['status'] = 'unchanged'  # Default status
    
    # Mark updated rows (rows where match_cols are the same but other columns differ)
    updated_mask = (merged_df['_merge'] == 'both') & (
        (merged_df.filter(regex='_old$').values != merged_df.filter(regex='_new$').values).any(axis=1)
    )
    merged_df.loc[updated_mask, 'status'] = 'updated'
    
    # Mark new rows (present in df_new but not in df_old)
    merged_df.loc[merged_df['_merge'] == 'right_only', 'status'] = 'new'
    
    # Mark removed rows (present in df_old but not in df_new)
    merged_df.loc[merged_df['_merge'] == 'left_only', 'status'] = 'removed'
    
    # Filter out only relevant rows (new, removed, and updated)
    diff_df = merged_df[merged_df['status'] != 'unchanged']
    
    # Keep only columns from the new DataFrame or columns in match_cols
    diff_df = diff_df.filter(regex='_new$|^' + '|^'.join(match_cols))
    diff_df.columns = [col.replace('_new', '') for col in diff_df.columns]  # Clean up column names
    
    # Reset index for cleaner output
    diff_df.reset_index(drop=True, inplace=True)
    
    return diff_df




import pandas as pd

def get_updated_rows(df_old: pd.DataFrame, df_new: pd.DataFrame, match_cols: list) -> pd.DataFrame:
    """
    Returns rows from df_new where there are differences from df_old based on all columns.
    Only rows with matching values in the specified match_cols are compared.
    
    Parameters:
    - df_old (pd.DataFrame): The original DataFrame.
    - df_new (pd.DataFrame): The new DataFrame with potential updates.
    - match_cols (list): List of columns used to identify matching rows.
    
    Returns:
    - pd.DataFrame: A DataFrame containing rows from df_new that differ from df_old.
    """
    
    # Merge the dataframes on the specified columns to identify updated rows
    merged_df = df_old.merge(df_new, on=match_cols, suffixes=('_old', '_new'), how='right', indicator=True)
    
    # Identify rows with differences in any column other than match_cols
    updated_rows = merged_df[merged_df['_merge'] == 'right_only']
    
    # Filter out columns ending with '_old' and rename columns back to original names
    updated_df = updated_rows.filter(regex='_new$').rename(columns=lambda x: x.replace('_new', ''))
    
    # Reset index for a clean output
    updated_df.reset_index(drop=True, inplace=True)
    
    return updated_df



import functools
import pickle
import os

class PersistentLRUCache:
    def __init__(self, maxsize=128, cache_file='cache.pkl'):
        self.cache_file = cache_file
        self.lru_cache = functools.lru_cache(maxsize=maxsize)(self._call_function)
        self.load_cache()

    def __call__(self, func):
        self.func = func
        return self.lru_cache

    def _call_function(self, *args, **kwargs):
        """Call the actual function with the cached behavior."""
        return self.func(*args, **kwargs)

    def save_cache(self):
        """Save the cache to a file."""
        with open(self.cache_file, 'wb') as f:
            # Export cache contents (internal cache and corresponding function arguments)
            cache_data = {
                'cache': self.lru_cache.cache_info(),
                'lru_cache': self.lru_cache.cache_clear()  # Save current state
            }
            pickle.dump(cache_data, f)

    def load_cache(self):
        """Load the cache from a file."""
        if os.path.exists(self.cache_file):
            with open(self.cache_file, 'rb') as f:
                cache_data = pickle.load(f)
                # Restore the cache data into the lru_cache (if possible)
                self.lru_cache.cache_clear()

    def cache_info(self):
        """Return cache statistics like hits and misses."""
        return self.lru_cache.cache_info()

    def clear_cache(self):
        """Clear the in-memory cache."""
        self.lru_cache.cache_clear()
        if os.path.exists(self.cache_file):
            os.remove(self.cache_file)


# Example usage of PersistentLRUCache

@PersistentLRUCache(maxsize=100, cache_file='my_lru_cache.pkl')
def expensive_function(x):
    print(f"Calculating for {x}...")
    return x * x

# Example usage
print(expensive_function(10))  # First time calculates and caches
print(expensive_function(10))  # Second time uses the cache

# Save the current cache state to disk
expensive_function.save_cache()

# Clear the cache (for example, restart of application)
expensive_function.clear_cache()

# Load the cache back from the file
expensive_function.load_cache()
print(expensive_function(10))  # Should load from the previously saved cache




import threading
import time
import sys

def periodic_function():
    try:
        while True:
            # Your periodic task here
            print("Running periodic task...")
            time.sleep(2)  # Simulate periodic work
            # Raise an exception to simulate failure
            raise Exception("Something went wrong in the daemon thread!")
    except Exception as e:
        print(f"Exception caught in daemon thread: {e}")
        # Allow the thread to terminate after catching the exception

def main():
    thread = threading.Thread(target=periodic_function, daemon=True)
    thread.start()

    try:
        while thread.is_alive():
            time.sleep(1)  # Main thread can do other work here

    except KeyboardInterrupt:
        print("Main program interrupted by user.")

    finally:
        print("Shutting down the program.")
        if not thread.is_alive():
            sys.exit(1)  # Exit the program with an error code

if __name__ == "__main__":
    main()





When interviewing a candidate for a Python role, asking questions that test both their understanding of language fundamentals and their ability to solve tricky problems is essential. Here are some challenging and thought-provoking Python interview questions:

1. Mutable Default Arguments

	•	Question: What happens when you use a mutable default argument (like a list or dictionary) in a function? How would you avoid issues with it?
	•	What it tests: Understanding of default argument behavior and potential bugs related to mutability.
	•	Answer: The default argument is evaluated only once, so if it’s modified (like appending to a list), the changes persist across function calls. To avoid this, use None as a default value and initialize inside the function.

2. Variable Scope and Closures

	•	Question: What is a closure in Python? Can you give an example?
	•	What it tests: Knowledge of how functions interact with their enclosing scopes and understanding of closures.
	•	Answer: A closure is a function that captures the local variables from its enclosing scope. Example:

def outer(x):
    def inner(y):
        return x + y
    return inner



3. The is vs == Operator

	•	Question: What is the difference between the is and == operators in Python?
	•	What it tests: Understanding of object identity (is) vs. equality (==).
	•	Answer: is checks for object identity (whether two references point to the same object in memory), while == checks for value equality (whether the values of the objects are the same).

4. Function Decorators

	•	Question: What is a decorator in Python? How would you write a decorator that prints the execution time of a function?
	•	What it tests: Understanding of higher-order functions and decorators.
	•	Answer: A decorator is a function that takes another function and extends its behavior without explicitly modifying it. Example of a timing decorator:

import time

def timer(func):
    def wrapper(*args, **kwargs):
        start_time = time.time()
        result = func(*args, **kwargs)
        end_time = time.time()
        print(f"Execution time: {end_time - start_time} seconds")
        return result
    return wrapper



5. Unpacking

	•	Question: How does unpacking work in Python, and what is extended unpacking (*)?
	•	What it tests: Understanding of tuple/list unpacking and advanced unpacking features.
	•	Answer: Unpacking assigns the values of a sequence to multiple variables. Extended unpacking (*) allows for capturing the remaining elements:

a, *b, c = [1, 2, 3, 4, 5]  # a = 1, b = [2, 3, 4], c = 5



6. GIL (Global Interpreter Lock)

	•	Question: What is the GIL in Python, and how does it affect multi-threaded programs?
	•	What it tests: Knowledge of Python’s concurrency model and limitations of the GIL in multi-threaded applications.
	•	Answer: The Global Interpreter Lock (GIL) is a mutex that protects access to Python objects, preventing multiple native threads from executing Python bytecodes at once. This means multi-threaded programs don’t benefit from parallel execution in CPU-bound tasks.

7. @staticmethod vs @classmethod

	•	Question: What is the difference between a @staticmethod and a @classmethod?
	•	What it tests: Understanding of object-oriented programming concepts in Python.
	•	Answer: A @staticmethod is a method that does not receive the instance (self) or the class (cls) as the first argument, while a @classmethod receives the class (cls) as the first argument, allowing it to modify class-level data.

8. Python Memory Management

	•	Question: How does Python manage memory? What are reference counting and garbage collection?
	•	What it tests: Understanding of Python’s memory management and garbage collection mechanism.
	•	Answer: Python uses reference counting to keep track of the number of references to each object. When the reference count drops to zero, the object is deallocated. Python also has a garbage collector that handles circular references.

9. List Comprehensions and Generator Expressions

	•	Question: What’s the difference between a list comprehension and a generator expression?
	•	What it tests: Understanding of memory efficiency and when to use one over the other.
	•	Answer: List comprehensions create a full list in memory, while generator expressions return an iterator that computes the items lazily, one at a time, making them more memory efficient.

10. Metaclasses

	•	Question: What is a metaclass in Python? How can you use a metaclass to change class behavior?
	•	What it tests: Advanced knowledge of Python’s class creation process.
	•	Answer: A metaclass is a class of a class, controlling the creation of classes. You can define custom behavior in the metaclass to influence how classes are created.

11. Coroutines and async/await

	•	Question: How do Python’s coroutines work? What is the purpose of async and await keywords?
	•	What it tests: Knowledge of asynchronous programming in Python.
	•	Answer: Coroutines are special functions that can pause and resume their execution using await. The async keyword is used to define a coroutine, and await is used to wait for asynchronous operations.

12. Python’s with Statement

	•	Question: What is the with statement, and how does it work internally?
	•	What it tests: Understanding of context managers and resource management.
	•	Answer: The with statement is used for resource management, such as opening and closing files. Internally, it uses context managers that implement the __enter__() and __exit__() methods to handle setup and cleanup.

13. Monkey Patching

	•	Question: What is monkey patching in Python? Is it a good practice?
	•	What it tests: Understanding of Python’s dynamic nature and potential pitfalls.
	•	Answer: Monkey patching is the practice of modifying or extending a class or module at runtime. It can be useful in certain situations but is generally discouraged as it can make the code harder to understand and maintain.

14. Comprehensions with Multiple for Loops

	•	Question: How would you write a list comprehension with multiple for loops and conditions?
	•	What it tests: Knowledge of Python’s comprehensions.
	•	Answer: You can nest for loops and include conditions in comprehensions:

result = [x * y for x in range(1, 4) for y in range(1, 3) if x * y > 2]



These types of questions will give you a good sense of the candidate’s depth of knowledge in Python, their understanding of common pitfalls, and their ability to write clean, efficient code.













apiVersion: batch/v1
kind: CronJob
metadata:
  name: scale-deployment-cronjob
spec:
  schedule: "0 10 * * 1-5"  # Every weekday at 10 AM
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: scale-deployment
            image: bitnami/kubectl:latest  # Lightweight kubectl image
            command:
            - /bin/sh
            - -c
            - |
              kubectl scale deployment <your-deployment-name> --replicas=0 -n <your-namespace> && \
              echo "Waiting for pods to terminate..." && \
              sleep 10 && \
              kubectl scale deployment <your-deployment-name> --replicas=1 -n <your-namespace>
          restartPolicy: OnFailure




import json
from datetime import datetime

def transform_json_list(json_list):
    result = [
        {
            'dv01': json.loads(j)['Col0']['0'],
            'maturity': datetime.fromordinal(json.loads(j)['Col0']['1'])
        }
        for j in json_list if j is not None
    ]
    return result




import dash
from dash import dcc, html
from dash_extensions import Clipboard
import dash_table
import pandas as pd

app = dash.Dash(__name__)

# Sample DataFrame
df = pd.DataFrame({
    "Column A": [1, 2, 3],
    "Column B": [4, 5, 6],
    "Column C": ["A", "B", "C"]
})

# Convert DataFrame to HTML table format (for copying)
df_string = df.to_csv(index=False)

app.layout = html.Div([
    # Display the DataFrame as a table
    dash_table.DataTable(
        id='table',
        columns=[{"name": i, "id": i} for i in df.columns],
        data=df.to_dict('records')
    ),

    # Hidden Textarea for copying the DataFrame as plain text (CSV format)
    dcc.Textarea(
        id='table-textarea',
        value=df_string,
        style={"display": "none"}  # Hide the textarea
    ),

    # Copy button
    html.Button("Copy Table to Clipboard", id="copy-button"),

    # Clipboard component to copy the content of the hidden textarea
    Clipboard(target_id="table-textarea"),
])

if __name__ == '__main__':
    app.run_server(debug=True)






from celery import Celery
from datetime import datetime, timedelta

# Initialize Celery
app = Celery('your_app_name')

def check_workers(worker_names):
    # Get the current state of workers
    inspect = app.control.inspect()
    active_workers = inspect.active()

    for worker in worker_names:
        print(f"Checking worker: {worker}")
        
        # Check if worker is active
        if worker not in active_workers:
            print(f"Worker {worker} is down or unresponsive.")
            continue
        
        # Ping the worker
        ping_response = app.control.ping([worker])
        if not ping_response or worker not in ping_response[0]:
            print(f"Worker {worker} did not respond to ping.")
            continue
        
        # Check heartbeat
        stats = inspect.stats()
        heartbeat = stats.get(worker, {}).get('heartbeat')
        if not heartbeat:
            print(f"Worker {worker} has no heartbeat.")
            continue
        
        # Get current time and convert heartbeat to datetime
        heartbeat_time = datetime.fromtimestamp(heartbeat)
        if datetime.now() - heartbeat_time > timedelta(minutes=2):  # Customize threshold if needed
            print(f"Worker {worker} heartbeat is outdated (last seen at {heartbeat_time}).")
            continue
        
        # Check the last task run time
        active_tasks = inspect.active([worker])[worker]
        if active_tasks:
            last_task_time = max(task['time_start'] for task in active_tasks)
            if datetime.now() - datetime.fromtimestamp(last_task_time) > timedelta(minutes=10):
                print(f"Worker {worker} has not run any task for over 10 minutes.")
            else:
                print(f"Worker {worker} is healthy.")
        else:
            print(f"No active tasks on worker {worker}, but it's healthy.")












To use WebSocket in your Dash app with the `dash-extensions` library, you need to replace the interval component and its callback with a WebSocket component that can handle real-time data updates. This way, the data will be pushed to the client as soon as it's available, reducing latency compared to polling with intervals.

Here's a basic example of how to implement this:

### 1. Install Necessary Packages
Make sure you have the necessary packages installed:

```bash
pip install dash dash-extensions
```

### 2. Basic WebSocket Example

```python
import dash
from dash import html, dcc, Output, Input
import dash_extensions as de
import time
import threading

# Sample data update function
def data_generator():
    while True:
        # Simulate some real-time data generation
        yield {"value": time.time()}
        time.sleep(1)  # Adjust frequency as needed

# Create the Dash app
app = dash.Dash(__name__)

# Layout with WebSocket component
app.layout = html.Div([
    de.WebSocket(id="ws", url="ws://127.0.0.1:8000/ws"),  # Replace with your WebSocket server URL
    html.Div(id="live-update-text"),
])

# Callback to update the text with WebSocket data
@app.callback(
    Output("live-update-text", "children"),
    Input("ws", "message")  # Trigger on WebSocket messages
)
def update_text(message):
    data = message["data"]
    return f"Updated value: {data['value']}"

# Run a background thread to simulate WebSocket server
def run_ws_server():
    from flask import Flask, jsonify
    from flask_sockets import Sockets
    from gevent import pywsgi
    from geventwebsocket.handler import WebSocketHandler

    server = Flask(__name__)
    sockets = Sockets(server)

    @sockets.route('/ws')
    def ws(ws):
        generator = data_generator()
        for data in generator:
            if not ws.closed:
                ws.send(jsonify(data).data)
            else:
                break

    # Start the WebSocket server
    server = pywsgi.WSGIServer(("0.0.0.0", 8000), server, handler_class=WebSocketHandler)
    server.serve_forever()

# Run the WebSocket server in a separate thread
thread = threading.Thread(target=run_ws_server)
thread.daemon = True
thread.start()

# Run the Dash app
if __name__ == '__main__':
    app.run_server(debug=True)
```

### Explanation

1. **WebSocket Component**: `de.WebSocket(id="ws", url="ws://127.0.0.1:8000/ws")`
   - This component connects to the WebSocket server at the specified URL. Replace the URL with your WebSocket server's URL.

2. **Callback with WebSocket Input**:
   - The callback is triggered every time a message is received from the WebSocket server (`Input("ws", "message")`).
   - `message["data"]` contains the data sent by the WebSocket server.

3. **Simulated WebSocket Server**:
   - For demonstration purposes, a WebSocket server is created using Flask-Sockets and run in a separate thread.
   - It uses the `data_generator()` function to simulate data updates.

### Customizing for Your Use Case

- **WebSocket Server URL**: Replace `"ws://127.0.0.1:8000/ws"` with your actual WebSocket server URL.
- **Data Format**: Modify the `data_generator()` and callback function as needed to handle your specific data format.

This approach can reduce latency since it pushes data updates to the client as soon as they're available.





NGINX provides various variables (`$values`) that you can use in your configuration to capture and log different aspects of the request and response. Here are some of the common variables available in NGINX:

### Common NGINX Variables

1. **Client Information:**
   - `$remote_addr`: Client IP address.
   - `$remote_port`: Client port.
   - `$remote_user`: User name supplied with the Basic Authentication.

2. **Request Details:**
   - `$request`: Full original request line.
   - `$request_body`: Full request body.
   - `$request_method`: Request method, e.g., `GET` or `POST`.
   - `$request_uri`: Full original request URI (with arguments).

3. **Headers:**
   - `$http_host`: Host name from the request header.
   - `$http_user_agent`: User-Agent header from the client.
   - `$http_referer`: Referer header from the client.
   - `$http_<header>`: Any other HTTP header (replace `<header>` with the header name, e.g., `$http_x_forwarded_for`).

4. **Response Details:**
   - `$status`: Response status code.
   - `$body_bytes_sent`: Number of bytes sent in the response body.
   - `$bytes_sent`: Total number of bytes sent to the client.

5. **Server Information:**
   - `$server_addr`: Server IP address.
   - `$server_port`: Server port.
   - `$server_protocol`: Protocol used, e.g., `HTTP/1.1`.

6. **Connection Information:**
   - `$connection`: Connection serial number.
   - `$connection_requests`: Number of requests made through this connection.

7. **Time and Date:**
   - `$time_local`: Local time in the Common Log Format.
   - `$msec`: Current time in seconds with milliseconds.

### Customizing Logs with Variables

You can use these variables to customize the log format in your NGINX configuration. For example:

```nginx
log_format custom '$remote_addr - $remote_user [$time_local] "$request" '
                  '$status $body_bytes_sent "$http_referer" '
                  '"$http_user_agent" "$http_x_forwarded_for"';
```

### Applying Custom Log Format in Ingress

If you want to use these variables in your Ingress annotations to log client IP and other details, you can specify a custom log format:

```yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: example-ingress
  namespace: your-namespace
  annotations:
    nginx.ingress.kubernetes.io/configuration-snippet: |
      log_format custom '$remote_addr - $http_x_forwarded_for [$time_local] "$request" '
                        '$status $body_bytes_sent "$http_referer" '
                        '"$http_user_agent" "$http_x_forwarded_for"';
    nginx.ingress.kubernetes.io/access-log-format: |
      '$remote_addr - $http_x_forwarded_for [$time_local] "$request" '
      '$status $body_bytes_sent "$http_referer" '
      '"$http_user_agent" "$http_x_forwarded_for"';
spec:
  rules:
  - host: example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: example-service
            port:
              number: 80
```

### Summary

NGINX provides a rich set of variables that you can use to capture various details about requests, responses, and client/server information. These variables can be used in log formats and configuration snippets to customize how NGINX handles and logs traffic, helping you get the specific details you need for monitoring and debugging.


-- Step 1: Create a sample table
CREATE TABLE sample_times (
    id NUMBER PRIMARY KEY,
    time VARCHAR2(6)
);

-- Step 2: Insert sample data
INSERT INTO sample_times (id, time) VALUES (1, '150000'); -- 15:00:00
INSERT INTO sample_times (id, time) VALUES (2, '160000'); -- 16:00:00
INSERT INTO sample_times (id, time) VALUES (3, '163000'); -- 16:30:00
INSERT INTO sample_times (id, time) VALUES (4, '164500'); -- 16:45:00

-- Step 3: Update times by adding 2 hours, but ensure they do not exceed '170000'
UPDATE sample_times
SET time = (
    SELECT TO_CHAR(
               TRUNC(LEAST((TO_NUMBER(SUBSTR(time, 1, 2)) * 3600 + 
                            TO_NUMBER(SUBSTR(time, 3, 2)) * 60 + 
                            TO_NUMBER(SUBSTR(time, 5, 2)) + 7200), 61200) / 3600, 0), 'FM00') ||
           TO_CHAR(
               TRUNC(MOD(LEAST((TO_NUMBER(SUBSTR(time, 1, 2)) * 3600 + 
                                TO_NUMBER(SUBSTR(time, 3, 2)) * 60 + 
                                TO_NUMBER(SUBSTR(time, 5, 2)) + 7200), 61200), 3600) / 60, 0), 'FM00') ||
           TO_CHAR(
               MOD(LEAST((TO_NUMBER(SUBSTR(time, 1, 2)) * 3600 + 
                          TO_NUMBER(SUBSTR(time, 3, 2)) * 60 + 
                          TO_NUMBER(SUBSTR(time, 5, 2)) + 7200), 61200), 60), 'FM00')
    FROM dual
);

-- Verify the update
SELECT * FROM sample_times;

nested_dict = {
    'a': {
        'b1': {'c1': 1, 'c2': 2, 'c3': 3},
        'b2': {'c4': 4, 'c5': 5, 'c6': 6}
    },
    'd': {
        'e1': {'f1': 7, 'f2': 8, 'f3': 9},
        'e2': {'f4': 10, 'f5': 11, 'f6': 12}
    }
}

nested_dict = {k1: {k2: {list(v3.items())[0][0]: list(v3.items())[0][1]} for k2, v3 in v2.items()} for k1, v2 in nested_dict.items()}

print(nested_dict)


nested_dict = {
    'a': {
        'b1': {'c1': 1, 'c2': 2, 'c3': 3},
        'b2': {'c4': 4, 'c5': 5, 'c6': 6}
    },
    'd': {
        'e1': {'f1': 7, 'f2': 8, 'f3': 9},
        'e2': {'f4': 10, 'f5': 11, 'f6': 12}
    }
}

nested_dict = {k1: {k2: {k3: v3[next(iter(v3))]} for k2, v3 in v2.items()} for k1, v2 in nested_dict.items()}

print(nested_dict)


Sure, I can explain how this process typically works.

### Smartcard Authentication

1. **Smartcard Login**: When you log in to your corporate laptop, you insert your smartcard into a card reader and enter a PIN. The smartcard contains a digital certificate that is used to authenticate you.

2. **Certificate Authentication**: The digital certificate on the smartcard is read by the system and used to authenticate you against the corporate network. This certificate contains your public key, and your private key remains on the card.

### Kerberos Authentication

1. **Initial Authentication Request**: Once your identity is verified through the smartcard, your computer sends an Authentication Service (AS) request to the Kerberos Key Distribution Center (KDC).

2. **Ticket Granting Ticket (TGT)**: The KDC verifies your credentials and issues a Ticket Granting Ticket (TGT), which is encrypted with a key derived from your password (in this case, your smartcard credentials).

3. **Service Ticket Request**: When you try to access an internal website or service, your computer uses the TGT to request a service ticket from the KDC for the specific service.

4. **Service Ticket**: The KDC issues a service ticket, which is encrypted with the service's key.

5. **Service Authentication**: Your computer presents the service ticket to the internal website or service, which decrypts the ticket and verifies your identity.

### Combined Workflow

1. **Smartcard and Kerberos Integration**: Your smartcard login credentials are used to obtain a Kerberos TGT. This TGT is then used to obtain service tickets for accessing internal websites and services without requiring you to re-enter your credentials.

2. **Single Sign-On (SSO)**: The combination of smartcard authentication and Kerberos provides a Single Sign-On (SSO) experience. Once you are logged into your laptop with your smartcard, you can access multiple internal resources without needing to re-authenticate.

### Security Advantages

1. **Strong Authentication**: The use of smartcards provides strong two-factor authentication (something you have - the card, and something you know - the PIN).

2. **Credential Protection**: Smartcards protect your private key and other credentials, making it difficult for attackers to steal them.

3. **Centralized Authentication**: Kerberos allows for centralized management of authentication, making it easier to enforce security policies and manage user access.

This process ensures secure and seamless access to internal resources while minimizing the need for multiple logins.


SELECT
    SUBSTR(email, 1, INSTR(email, '.') - 1) AS Firstname,
    SUBSTR(email, INSTR(email, '.') + 1, INSTR(email, '@') - INSTR(email, '.') - 1) AS Lastname
FROM
    your_table;

def reverse_transform(inverted_dict):
    # Initialize the output dictionary
    output_dict = {}

    # Iterate through the outer dictionary of the inverted structure
    for key3, sub_dict1 in inverted_dict.items():
        for key1, sub_dict2 in sub_dict1.items():
            for key2, value in sub_dict2.items():
                # Ensure key1 is in the outer dictionary of the output
                if key1 not in output_dict:
                    output_dict[key1] = {}
                # Ensure key2 is in the dictionary corresponding to key1
                if key2 not in output_dict[key1]:
                    output_dict[key1][key2] = {}
                # Set the value
                output_dict[key1][key2][key3] = value

    return output_dict

# Example usage:
inverted_dict = {
    'k1': {
        'A': {'a1': 1, 'a2': 3},
        'B': {'b2': 7}
    },
    'k2': {
        'A': {'a1': 2},
        'B': {'b1': 5, 'b2': 8}
    },
    'k3': {
        'A': {'a2': 4},
        'B': {'b1': 6}
    }
}

output_dict = reverse_transform(inverted_dict)
print(output_dict)






def inverse_dict(input_dict):
    # Initialize the output dictionary
    output_dict = {}

    # Iterate through the outer dictionary
    for key1, sub_dict1 in input_dict.items():
        for key2, sub_dict2 in sub_dict1.items():
            for key3, value in sub_dict2.items():
                # Ensure the key3 is in the outer dictionary of the output
                if key3 not in output_dict:
                    output_dict[key3] = {}
                # Ensure key1 is in the dictionary corresponding to key3
                if key1 not in output_dict[key3]:
                    output_dict[key3][key1] = {}
                # Set the value
                output_dict[key3][key1][key2] = value

    return output_dict

# Example usage:
input_dict = {
    'A': {
        'a1': {'k1': 1, 'k2': 2},
        'a2': {'k1': 3, 'k3': 4}
    },
    'B': {
        'b1': {'k2': 5, 'k3': 6},
        'b2': {'k1': 7, 'k2': 8}
    }
}

output_dict = inverse_dict(input_dict)
print(output_dict)


import time
from datetime import datetime, timedelta

def sleep_until_next_day():
    now = datetime.now()
    # Calculate the next midnight
    next_midnight = (now + timedelta(days=1)).replace(hour=0, minute=0, second=0, microsecond=0)
    # Calculate the number of seconds to sleep
    time_to_sleep = (next_midnight - now).total_seconds()
    print(f"Sleeping for {time_to_sleep} seconds until next day")
    time.sleep(time_to_sleep)

# Example usage
if __name__ == "__main__":
    print("Current time:", datetime.now())
    sleep_until_next_day()
    print("Woke up at:", datetime.now())


Using threads is a common approach, but if you want more control over scheduling and better performance, especially if your tasks are I/O-bound rather than CPU-bound, you might consider using the `concurrent.futures` module with `ThreadPoolExecutor` or `asyncio` for asynchronous execution.

Here's how you can use `concurrent.futures.ThreadPoolExecutor`:

```python
import concurrent.futures
import time

def function_1():
    while True:
        # Your code for function 1
        print("Function 1 is running")
        time.sleep(1)

def function_2():
    while True:
        # Your code for function 2
        print("Function 2 is running")
        time.sleep(1)

def run_periodically(executor, func):
    future = executor.submit(func)
    future.add_done_callback(lambda f: run_periodically(executor, func))

# Create a ThreadPoolExecutor
with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
    run_periodically(executor, function_1)
    run_periodically(executor, function_2)

    # Keep the main thread alive to allow periodic execution
    try:
        while True:
            time.sleep(1)
    except KeyboardInterrupt:
        print("Stopped by user")
```

In this example:

1. `run_periodically` submits a function to the executor and re-submits it once it's done, creating a periodic execution loop.
2. `ThreadPoolExecutor` manages the threads for you and allows better control over the number of concurrent threads.

Alternatively, you can use `asyncio` for asynchronous execution:

```python
import asyncio

async def function_1():
    while True:
        # Your code for function 1
        print("Function 1 is running")
        await asyncio.sleep(1)

async def function_2():
    while True:
        # Your code for function 2
        print("Function 2 is running")
        await asyncio.sleep(1)

async def main():
    # Schedule the periodic tasks
    task1 = asyncio.create_task(function_1())
    task2 = asyncio.create_task(function_2())
    
    # Keep the main task alive
    await asyncio.gather(task1, task2)

# Run the asyncio event loop
asyncio.run(main())
```

In this example:

1. `asyncio` runs coroutines (`function_1` and `function_2`) asynchronously.
2. `asyncio.create_task` schedules the coroutines to run concurrently.
3. `asyncio.run(main())` starts the asyncio event loop, executing the main coroutine which gathers the periodic tasks.

Using `asyncio` can be more efficient than threading for I/O-bound tasks since it doesn't require as many system resources and can handle a larger number of concurrent tasks.






### Functional Specifications Document (FSD)

**Project Title**: Data Feed Detection, Onboarding, and Reconciliation Application

**Prepared by**: [Your Name]

**Date**: [Date]

---

#### 1. Introduction

**1.1 Purpose**

This document provides the functional specifications for an application designed to detect new data feeds entering a database, initiate a workflow for onboarding and approval, and perform reconciliation to ensure the accuracy and completeness of data used by production surveillance models. The application aims to streamline the detection and onboarding process, improve data governance, and ensure regulatory compliance.

**1.2 Scope**

The application will:
- Detect new data feeds based on daily load logs.
- Notify database administrators and require their input on the new feeds.
- Notify surveillance business analysts for compliance review and onboarding status.
- Detect persistency tables used by production surveillance models.
- Perform reconciliation to detect mismatches and potential gaps between detected data feeds and persistency tables.

#### 2. Functional Requirements

**2.1 Data Feed Detection**

- The application will scan the database daily to detect any new tables with successfully loaded data. This ensures timely awareness of new data sources.
- Detection will be based on the analysis of load logs stored in the database, which log the status of data loads.

**2.2 Workflow Initiation**

- Upon detection of a new data feed, the application will automatically send an email notification to the database administrators.
- A workflow will be initiated, requiring the database administrators to fill out specific information about the new feed, ensuring that all necessary details are captured for further processing.

**2.3 Administrator Dashboard**

- A dedicated section for database administrators will be available in the dashboard. This provides a centralized location for managing new data feeds.
- Database administrators must provide the following details:
  - Loader name
  - Frequency
  - Data type
  - Upstream source application ID
  - Upstream source application name
  - Persistency table and schema
- Database administrators must also approve whether the source is relevant for regulatory purposes, such as trade, pre-trade, or market data. This ensures that only pertinent data is flagged for regulatory scrutiny.

**2.4 Notification to Surveillance Business Analysts**

- After database administrators complete their input, surveillance business analysts will receive an email notification.
- Analysts will access a dedicated subsection in the dashboard to analyze the new feed. This ensures a systematic review process by the compliance teams.

**2.5 Analyst Review**

- Surveillance business analysts, along with the FOCS and compliance teams, will review the new feed.
- Analysts will determine whether the new feed should be used for surveillance models. This step is crucial for maintaining the integrity of surveillance systems.
- Analysts will provide a status update on the onboarding process, ensuring transparency and accountability.

**2.6 Persistency Table Detection and Reconciliation**

- The application will detect persistency tables used by production surveillance models.
- A reconciliation process will compare these tables with the detected data feeds to identify mismatches and potential gaps.
- Any discrepancies will be flagged for further investigation and resolution, ensuring data consistency and completeness.

#### 3. Non-Functional Requirements

**3.1 Performance**

- The application should detect new data feeds and send notifications within 24 hours of data load completion.
- The dashboard should load within 2 seconds for all users, ensuring a smooth user experience.
- The reconciliation process should complete within a reasonable timeframe (e.g., within 1 hour of initiation) to maintain efficiency.

**3.2 Security**

- Only authorized personnel (database administrators and surveillance business analysts) should have access to the respective sections of the dashboard.
- Data integrity and confidentiality must be maintained throughout the process, protecting sensitive information.

**3.3 Usability**

- The user interface should be intuitive and easy to navigate, minimizing the learning curve for users.
- Clear instructions and error messages should be provided to guide users through the process, enhancing user experience.

**3.4 Reliability**

- The system should have 99.9% uptime, ensuring continuous availability.
- Robust error handling and logging mechanisms should be in place to track any issues, aiding in prompt resolution.

#### 4. System Architecture

**4.1 Components**

- **Data Feed Detection Module**: Scans the database and detects new data feeds.
- **Notification Module**: Sends email notifications to relevant stakeholders.
- **Administrator Dashboard**: Interface for database administrators to provide details and approvals.
- **Analyst Dashboard**: Interface for surveillance business analysts to review and approve feeds.
- **Reconciliation Module**: Compares persistency tables with detected data feeds and identifies discrepancies.

**4.2 Integration**

- The application will integrate with the existing database to access load logs and data feeds.
- Email notifications will be sent via the corporate email system.
- The dashboard will be part of the existing web application, ensuring a seamless user experience.

#### 5. User Interface

**5.1 Administrator Dashboard**

- Sections for entering feed details, ensuring comprehensive data capture.
- Approval buttons for regulatory relevance, simplifying the approval process.

**5.2 Analyst Dashboard**

- Sections for reviewing feed information, facilitating thorough analysis.
- Status update fields, ensuring clear communication and tracking.

**5.3 Reconciliation Dashboard**

- Display detected persistency tables and comparison results.
- Highlight mismatches and gaps for investigation, aiding in quick resolution.

#### 6. Workflow Diagram

**Workflow Representation**

1. **Data Feed Detection**:
   - The system scans the database daily.
   - New tables with successfully loaded data are detected.

2. **Notification and Workflow Initiation**:
   - Email notifications are sent to database administrators.
   - Administrators access the dashboard to provide feed details.

3. **Administrator Input**:
   - Administrators fill in details such as loader name, frequency, data type, etc.
   - Approval for regulatory relevance is provided.

4. **Notification to Analysts**:
   - Email notifications are sent to surveillance business analysts.
   - Analysts access the dashboard to review new feeds.

5. **Analyst Review**:
   - Analysts review feed information and determine its relevance for surveillance models.
   - Analysts update the status of the feed onboarding process.

6. **Persistency Table Detection**:
   - The system detects persistency tables used by production surveillance models.

7. **Reconciliation Process**:
   - Detected persistency tables are compared with data feeds.
   - Mismatches and gaps are identified and flagged for investigation.

---

**Signatures**

*Prepared by:*
[Your Name]

*Reviewed by:*
[Reviewer Name]

*Approved by:*
[Approver Name]

---

This FSD outlines the functional requirements and specifications for the Data Feed Detection, Onboarding, and Reconciliation Application. This ensures all new data feeds are properly detected, reviewed, reconciled, and utilized for compliance purposes, enhancing data governance and regulatory adherence.










# Functional Specification Document (FSD)

## 1. Introduction

### 1.1 Purpose
This document details the functional specifications for an application designed to trace data filtered during pre-processing before surveillance models run. The application includes a configurable dashboard for data consultation and lineage visualization. It aims to provide transparency and traceability by identifying filtered messages and displaying their flow from source to alert generation.

### 1.2 Scope
The application allows users to configure data sources, define filtering rules, and compare data to detect and justify filtered messages. It also provides a data lineage view to track data flow from the data source to the alert generation phase. This tool is intended for database administrators and surveillance business analysts who need to understand data filtering processes and ensure data integrity and compliance.

### 1.3 Definitions, Acronyms, and Abbreviations
- **FSD:** Functional Specification Document
- **ID:** Identifier
- **UI:** User Interface
- **Datamart:** A subset of a data warehouse focused on a particular area of interest.

### 1.4 References
- [Surveillance Model Documentation]
- [Database Schema]
- [User Guide]

## 2. Overall Description

### 2.1 Product Perspective
The application integrates into the existing surveillance system, enhancing data transparency and traceability by identifying filtered messages and providing detailed lineage from data sources to alert generation. It serves as a crucial tool for monitoring and ensuring the accuracy and reliability of data used in surveillance models.

### 2.2 Product Functions
- Configure data sources and target tables.
- Define and apply filtering rules.
- Compare data to detect filtered messages.
- Display counts of filtered rows.
- Provide technical and functional justifications for filtered messages.
- Visualize data lineage from source to alert generation.

### 2.3 User Characteristics
The primary users are database administrators and surveillance business analysts who require insights into data filtering and flow within the surveillance system. These users typically have a technical background and are responsible for maintaining data integrity, compliance, and performance of surveillance models.

### 2.4 Assumptions and Dependencies
- The application assumes access to the required databases and tables.
- Dependencies include the underlying database management system and the existing surveillance models.
- The system should be compatible with the data formats and schemas used in the current surveillance infrastructure.

## 3. Functional Requirements

### 3.1 Data Source Configuration

#### 3.1.1 Description
Users can configure the source of data, including the selection of the persistency table and the target datamart table name. This configuration allows the application to retrieve and process the relevant data for analysis.

#### 3.1.2 Inputs
- Source table name
- Persistency table name
- Target datamart table name

#### 3.1.3 Processing
The application stores the configuration settings and uses them to access the necessary tables. It retrieves data from the source table and persistency table, then prepares it for comparison against the target datamart table.

#### 3.1.4 Outputs
- Confirmation message on successful configuration
- Error messages for invalid inputs
- Log entries detailing the configuration process

### 3.2 Data Filtering and Comparison

#### 3.2.1 Description
The application traces and compares data to detect filtered messages by utilizing a message ID column. It identifies discrepancies between the source and target tables, highlighting messages that have been filtered out during pre-processing.

#### 3.2.2 Inputs
- Message ID column
- Filtering rules

#### 3.2.3 Processing
The application performs a comparison of data between the source, persistency, and target tables based on the message ID column. It identifies filtered messages and counts the number of rows filtered out during the pre-processing stage.

#### 3.2.4 Outputs
- Count of filtered rows
- Detailed logs of filtered messages, including their IDs and reasons for filtering
- Reports summarizing the filtering results

### 3.3 Filtering Rules

#### 3.3.1 Description
Users can define filtering rules to justify filtered messages both technically and functionally. These rules determine which messages are filtered out during pre-processing based on specific conditions.

#### 3.3.2 Inputs
- Rule name
- Condition (e.g., message type, value thresholds)

#### 3.3.3 Processing
The application applies the defined rules to filter data during the pre-processing stage. It evaluates each message against the filtering conditions and marks those that meet the criteria as filtered.

#### 3.3.4 Outputs
- Report or log of applied filtering rules and their results
- Justification for each filtered message based on the applied rules

### 3.4 Dashboard and Data Lineage

#### 3.4.1 Description
The dashboard provides functionalities including a data lineage section that visualizes data flow from the source to alert generation. Users can consult the dashboard to see the entire lifecycle of data, from initial ingestion to final alert generation.

#### 3.4.2 Inputs
- Data source configuration
- Filtering results

#### 3.4.3 Processing
The application compiles and displays data lineage information and filtering results on the dashboard. It aggregates data from different stages of the process to provide a comprehensive view of data flow and filtering activities.

#### 3.4.4 Outputs
- Visual representations of data flow
- Counts of alerts generated
- Interactive charts and graphs showing data lineage and filtering metrics

## 4. System Features

### 4.1 User Interface
The UI includes sections for data source configuration, filtering rules definition, data comparison results, and data lineage visualization. It is designed to be intuitive and user-friendly, allowing users to easily navigate and access the functionalities they need.

### 4.2 Reports
The application generates detailed reports that include filtered messages, applied rules, and data lineage. These reports can be used for auditing, compliance, and performance analysis.

### 4.3 Notifications
The application provides notifications for configuration changes, filtering results, and system errors. These notifications help users stay informed about important events and potential issues.

### 4.4 Data Export
Users can export data and reports in formats such as CSV and PDF. This feature allows users to share information with stakeholders and perform further analysis outside the application.

## 5. Non-Functional Requirements

### 5.1 Performance Requirements
- The application should respond to user actions within 2 seconds.
- Data comparison and filtering processes should complete within 1 minute for typical datasets.
- The system should handle large volumes of data efficiently, ensuring timely processing and analysis.

### 5.2 Security Requirements
- User authentication and authorization are required for access.
- Data should be encrypted in transit and at rest.
- The application should comply with relevant data protection regulations and industry standards.

### 5.3 Usability Requirements
- The application should have an intuitive and user-friendly interface.
- Accessible for users with varying levels of technical expertise.
- The design should prioritize clarity, ease of use, and efficient navigation.

### 5.4 Reliability Requirements
- The application should have an uptime of 99.9%.
- Error handling should ensure graceful degradation and informative error messages.
- The system should provide robust logging and monitoring to facilitate troubleshooting and maintenance.

### 5.5 Maintainability Requirements
- The application should support easy updates and configuration changes.
- Documentation should be provided for maintenance and support.
- The codebase should be modular and well-documented to facilitate future enhancements and debugging.

## 6. Appendices

### 6.1 Glossary
- **Filtered Message:** A message that has been excluded based on predefined rules.
- **Data Lineage:** The historical and chronological flow of data from source to destination.
- **Persistency Table:** A table that stores intermediate data during processing.
- **Datamart:** A subset of a data warehouse focused on a particular area of interest.

### 6.2 Diagrams
- **Data Flow Diagram:** (Include diagram showing data flow from source to alerts generation)
- **Architecture Diagram:** (Include diagram showing the system architecture)

### 6.3 Sample Data
- **Input Data Example:** (Provide sample input data)
- **Output Data Example:** (Provide sample output data)

### 6.4 References
- [Surveillance Model Documentation]
- [Database Schema]
- [User Guide]

---

This revised FSD includes more detailed explanations of each process, providing a comprehensive overview of the application's functionalities and requirements.





